{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Working with Scenes\n",
    "\n",
    "After having retrieved a scene from a dataset, we can access a couple of properties as well as child objects.\n",
    "Let's start with scene properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Quick prep work from previous tutorials:\n",
    "\n",
    "from paralleldomain.decoding.dgp.decoder import DGPDatasetDecoder\n",
    "from paralleldomain.model.dataset import Dataset  # optional import, just for type reference in this tutorial\n",
    "from paralleldomain.model.scene import Scene  # optional import, just for type reference in this tutorial\n",
    "\n",
    "dataset_path = \"s3://pd-sdk-c6b4d2ea-0301-46c9-8b63-ef20c0d014e9/testset_dgp\"\n",
    "dgp_decoder = DGPDatasetDecoder(dataset_path=dataset_path)\n",
    "\n",
    "dataset: Dataset = dgp_decoder.get_dataset()\n",
    "scene: Scene = dataset.get_scene(scene_name=dataset.scene_names[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'PD': { '@type': 'type.googleapis.com/dgp.proto.ParallelDomainSceneMetadata',\n",
      "          'batch_id': 0,\n",
      "          'cloud_cover': 0.10000000149011612,\n",
      "          'fog_intensity': 0.0,\n",
      "          'location': 'SF_6thAndMission_medium',\n",
      "          'rain_intensity': 0.0,\n",
      "          'region_type': 'NORTHERN_CALIFORNIA',\n",
      "          'scene_type': 'URBAN',\n",
      "          'street_lights': 0.0,\n",
      "          'sun_azimuth': 0,\n",
      "          'sun_elevation': 0,\n",
      "          'time_of_day': 'LS_sky_noon_partlyCloudy_1113_HDS024',\n",
      "          'version': 0,\n",
      "          'wetness': 0}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import PrettyPrinter\n",
    "\n",
    "\n",
    "# Use prettyprint for nested dictionaries\n",
    "pp = PrettyPrinter(indent=2)\n",
    "pp.pprint(scene.metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scene metadata usually contains any variables that changes with each scene and are not necessarily consistent across a whole data.\n",
    "In many cases these are environment variables like weather, time of day and location.\n",
    "\n",
    "A `Scene` object also includes the information of the available annotation types. These be consistent in most datasets with the ones on the `Dataset` level, but there is the possibility to vary them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ <class 'paralleldomain.model.annotation.BoundingBoxes2D'>,\n",
      "  <class 'paralleldomain.model.annotation.BoundingBoxes3D'>,\n",
      "  <class 'paralleldomain.model.annotation.SemanticSegmentation2D'>,\n",
      "  <class 'paralleldomain.model.annotation.SemanticSegmentation3D'>,\n",
      "  <class 'paralleldomain.model.annotation.InstanceSegmentation2D'>,\n",
      "  <class 'paralleldomain.model.annotation.InstanceSegmentation3D'>,\n",
      "  <class 'paralleldomain.model.annotation.Depth'>,\n",
      "  <class 'paralleldomain.model.annotation.Annotation'>,\n",
      "  <class 'paralleldomain.model.annotation.Annotation'>,\n",
      "  <class 'paralleldomain.model.annotation.OpticalFlow'>,\n",
      "  <class 'paralleldomain.model.annotation.Annotation'>]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(scene.available_annotation_types)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normally, in a scene, we expect to have more than one frame available, especially when we work with sequential data.\n",
    "These can be accessed through their frame IDs. In DGP datasets, these are usually string representations of increasing integers, but they could be also more explicit identifiers for other datasets, e.g., a string representation of a UNIX time or recording vehicle details included.\n",
    "\n",
    "In our example, the frame IDs follow the pattern of integers in string representation:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd-sdk_test_set has 10 frames available.\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{scene.name} has {len(scene.frame_ids)} frames available.\")\n",
    "print(scene.frame_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A `Frame` object is like a timestamp-bracket around different sensor data. If we have multiple sensors mounted on our recording vehicle, then the single data recordings are usually grouped into specific timestamps.\n",
    "We can retrieve a `Frame` object and actually see what the \"grouping datetime\" is:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-22 15:16:21.367000+00:00\n"
     ]
    }
   ],
   "source": [
    "frame_0 = scene.get_frame(frame_id=\"0\")\n",
    "print(frame_0.date_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Date/Times are presented as Python's std library `datetime` objects. When decoding data, the PD SDK also adds timezone information to these objects.\n",
    "\n",
    "As a next step, we want to see what sensor are available within that scene. In general, sensors are divided into `CameraSensor` and `LidarSensor`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cameras:\n",
      "camera_front\n",
      "camera_rear\n",
      "virtual_lidar_front_camera_0\n",
      "virtual_lidar_front_camera_1\n",
      "virtual_lidar_front_camera_2\n",
      "virtual_lidar_rear_camera_0\n",
      "virtual_lidar_rear_camera_1\n",
      "virtual_lidar_rear_camera_2\n",
      "\n",
      "\n",
      "LiDARs:\n",
      "lidar_front\n",
      "lidar_rear\n"
     ]
    }
   ],
   "source": [
    "print(\"Cameras:\", *scene.camera_names, sep='\\n')\n",
    "print(\"\\n\")\n",
    "print(\"LiDARs:\", *scene.lidar_names, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similar one how we used this information to get a scene from a dataset, we can use this to get a sensor from a scene."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_camera_sensor() got an unexpected keyword argument 'camera_name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_49475/2967055107.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mcamera_0_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscene\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcamera_names\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mcamera_0\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscene\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_camera_sensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcamera_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcamera_0_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m: get_camera_sensor() got an unexpected keyword argument 'camera_name'"
     ]
    }
   ],
   "source": [
    "camera_0_name = scene.camera_names[0]\n",
    "camera_0 = scene.get_camera_sensor(camera_name=camera_0_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Knowing which frames and sensors are available allows us to now query for the actual sensor data.\n",
    "As described above, a `Frame` is the time-grouping bracket around different sensor recordings. The actual data for a specific sensor assigned to this represented in a `SensorFrame`.\n",
    "This is where sensor data and annotations live.\n",
    "\n",
    "We can either first select a `Frame` and then pick a `Sensor` or the otherway around."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "camera_frame_via_frame = frame_0.get_camera(camera_name=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "set()"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_0.frame_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}